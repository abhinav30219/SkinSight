# Training configuration for ConvNeXt skin lesion classifier

# Model configuration
model:
  name: "facebook/convnext-base-224"
  model_type: "convnext"  # Will need to create adapter for this
  num_classes: 7
  dropout_rate: 0.1
  use_augmentation: true
  use_lora: true  # Parameter-efficient fine-tuning
  lora_config:
    r: 8
    lora_alpha: 32
    lora_dropout: 0.05
    target_modules:
      - "downsample.0.conv"
      - "conv_dw"
      - "pointwise"
      - "mlp.fc1"
      - "mlp.fc2"

# Data configuration
data:
  metadata_path: "../../HAM10000/HAM10000_metadata.csv"
  image_dirs:
    - "../../HAM10000/HAM10000_images_part_1"
    - "../../HAM10000/HAM10000_images_part_2"
  split_path: "data_splits.json"
  batch_size: 2
  num_workers: 0  # Set to 0 for MPS compatibility
  use_weighted_sampling: true
  input_size: 224  # Standard size

# Training configuration
training:
  num_epochs: 10
  learning_rate: 0.00002  # 2e-5
  warmup_steps: 200
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  fp16: true
  eval_steps: 100
  save_steps: 500
  save_epochs: 2
  logging_steps: 10
  early_stopping_patience: 3
  max_grad_norm: 1.0
  
# Optimizer configuration
optimizer:
  type: "adamw"
  weight_decay: 0.01
  adam_epsilon: 0.00000001  # 1e-8
  adam_beta1: 0.9
  adam_beta2: 0.999

# Scheduler configuration
scheduler:
  type: "cosine"
  num_warmup_steps: 500
  num_training_steps: null  # Will be calculated based on dataset size

# Output configuration
output:
  model_dir: "./checkpoints/convnext"
  log_dir: "./logs/convnext"
  best_model_dir: "./best_model_convnext"

# Device configuration
device:
  type: "mps"  # Use "cuda" for NVIDIA GPUs, "cpu" for CPU
  mixed_precision: true

# Evaluation configuration
evaluation:
  compute_metrics: true
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision_macro"
    - "recall_macro"
    - "confusion_matrix"

# Seed for reproducibility
seed: 42
